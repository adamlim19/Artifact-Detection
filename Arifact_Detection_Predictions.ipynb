{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWYH5qLMawXk0bkSAo9cr6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamlim19/Artifact-Detection/blob/main/Arifact_Detection_Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzyLQrda3yUZ",
        "outputId": "bb2d7add-bd9e-4701-f04d-4954f606221e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fpSK09b3LG2"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Conv2D, Flatten, concatenate, MaxPooling2D, AveragePooling2D, Dropout, Activation, Add, Multiply, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n",
        "import keras.backend as K\n",
        "from keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "#loading dataset\n",
        "def normalize_img(img):\n",
        "    img = tf.cast(img, dtype=tf.float32)\n",
        "    # Map values in the range [-1, 1]\n",
        "    return (img/tf.squeeze(img).numpy().max())\n",
        "\n",
        "train = pd.read_csv('/content/gdrive/My Drive/labels_final.csv')\n",
        "train = pd.DataFrame(train)\n",
        "print(train)\n",
        "\n",
        "train_image = []\n",
        "for i in range(train.shape[0]):\n",
        "    img = tf.keras.preprocessing.image.load_img('/content/gdrive/My Drive/Images/'+train['Id'][i], color_mode=\"grayscale\",target_size=(512,512))\n",
        "    img = image.img_to_array(img)\n",
        "    img = normalize_img(img)\n",
        "    train_image.append(img)\n",
        "X = np.array(train_image)\n",
        "\n",
        "#importing classification model\n",
        "\n",
        "def Hamming_loss(y_true, y_pred):\n",
        "    tmp = K.abs(y_true-y_pred)\n",
        "    return K.mean(K.cast(K.greater(tmp,0.5),dtype=float))\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    p = precision(y_true, y_pred)\n",
        "    r = recall(y_true, y_pred)\n",
        "    return 2*((p*r)/(p+r+K.epsilon()))\n",
        "\n",
        "y=np.array(train.drop(['Id'], axis=1))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.20, random_state=42)\n",
        "\n",
        "model = tf.keras.models.load_model('/content/gdrive/My Drive/classification_epoch-89-val_loss-0.00068016-val_acc-0.98222.h5', custom_objects={'Hamming_loss': Hamming_loss, 'recall': recall, 'precision': precision, 'f1': f1})\n",
        "model.summary()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', Hamming_loss, recall, precision, f1])\n",
        "\n",
        "predictions_class = model.predict(X_test)\n",
        "\n",
        "#importing severity model\n",
        "def q_loss(q,y,f):\n",
        "    f = tf.cast(f, tf.float32)\n",
        "    y = tf.cast(y, tf.float32)\n",
        "    e = (y-f)\n",
        "    return K.mean(K.maximum(q*e, (q-1)*e), axis=-1)\n",
        "model = tf.keras.models.load_model('/content/gdrive/My Drive/Regression_epoch-83-val_loss-0.32475540.h5', compile = False)\n",
        "model.summary()\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "model.compile(optimizer=opt, loss=lambda y,f: q_loss(0.90,y,f))\n",
        "ypred = model.predict(X_test)\n",
        "\n",
        "#normalizing predictions\n",
        "for i in range(len(X_test)):\n",
        "  ypred[i,0] = ypred[i,0]+0.5\n",
        "  ypred[i,1] = ypred[i,1]+0.5\n",
        "  ypred[i,2] = ypred[i,2]+0.5\n",
        "\n",
        "for i in range(len(X_test)):  \n",
        "    if ypred[i,0]>1.75:\n",
        "      ypred[i,0] = ypred[i,0] + 0.75\n",
        "    if ypred[i,0]>1.5 and ypred[i,0]<1.75:\n",
        "      ypred[i,0] = ypred[i,0] + 0.5\n",
        "    if ypred[i,0]<1:\n",
        "      ypred[i,0] = ypred[i,0]-0.75\n",
        "      \n",
        "    if ypred[i,1]>2.25:\n",
        "      ypred[i,1] = ypred[i,1] + 0.5\n",
        "    if ypred[i,1]<1.75:\n",
        "      ypred[i,1] = ypred[i,1]-0.75\n",
        "      \n",
        "    if ypred[i,2]>2.25:\n",
        "      ypred[i,2] = ypred[i,2] + 0.5\n",
        "    if ypred[i,2]>1.5 and ypred[i,2]<1.75:\n",
        "      ypred[i,2] = ypred[i,2]-0.5\n",
        "    if ypred[i,2]<1.5:\n",
        "      ypred[i,2] = ypred[i,2]-0.25\n",
        "print(ypred)\n",
        "\n",
        "#getting output predictions\n",
        "for j in range(0,len(X_test)):\n",
        "    score_motion = predictions_class[j][0] * ypred[j][0]\n",
        "    score_cs = predictions_class[j][1] * ypred[j][1]\n",
        "    score_rf = predictions_class[j][2] * ypred[j][2]\n",
        "    print(score_motion, ' ', score_cs, ' ', score_rf)\n",
        "    plt.imshow(np.squeeze(X_test[j]), cmap=\"gray\")\n",
        "    plt.show()   \n",
        "    if score_motion>=2:\n",
        "      print('Severe Motion')\n",
        "    if score_motion>=1 and score_motion<2:\n",
        "      print('Medium Motion')\n",
        "    if score_motion<1 and score_motion>0.5:\n",
        "      print('Mild Motion')\n",
        "    if score_motion<=0.5:\n",
        "      print('No Motion')\n",
        "    if score_cs>=2:\n",
        "      print('Severe cs')\n",
        "    if score_cs>=1 and score_cs<2:\n",
        "      print('Medium cs')\n",
        "    if score_cs<1 and score_cs>0.5:\n",
        "      print('Mild cs')\n",
        "    if score_cs<=0.5:\n",
        "      print('No cs')\n",
        "    if score_rf>=2:\n",
        "      print('Severe rf')\n",
        "    if score_rf>=1 and score_rf<2:\n",
        "      print('Medium rf')\n",
        "    if score_rf<1 and score_rf>0.5:   \n",
        "      print('Mild rf')\n",
        "    if score_rf<=0.5:\n",
        "      print('No rf')\n",
        "    print(' ')"
      ]
    }
  ]
}